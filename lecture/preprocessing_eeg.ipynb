{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Introduction to EEG-preprocessing\n",
    "## Methodological working in imaging neuroscience\n",
    "### Summer Term 2021   \n",
    "\n",
    "\n",
    "[José C. García Alanis (he/him)](https://github.com/JoseAlanis)\n",
    "<br>\n",
    "Research Fellow - [Dep. of Psychology](https://www.uni-marburg.de/en/fb04/department) at [Uni Marburg](https://www.uni-marburg.de/en).\n",
    "<br>\n",
    "Affiliated - [Child and Adolescent Psychology](https://www.uni-marburg.de/en/fb04/workgroups/pediatric-and-adolescent-psychology), [RTG Breaking Expectations](https://www.uni-marburg.de/en/fb04/rtg-2271).\n",
    "<br>\n",
    "\n",
    "31/05/2021\n",
    "\n",
    "<img align=\"left\" src=\"https://raw.githubusercontent.com/G0RELLA/gorella_mwn/master/lecture/static/GitHub-Mark-120px-plus.png\" alt=\"logo\" title=\"Github\" width=\"30\" height=\"10\" /> \n",
    "\n",
    "<img align=\"right\" src=\"http://learn.neurotechedu.com/images/filtered_unfiltered.png\" alt=\"logo\"  title=\"pdf_x\" width=\"550\" height=\"500\" />\n",
    "\n",
    "\n",
    "&nbsp;&nbsp;@JoseAlanis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Before we get started\n",
    "\n",
    "This materials are inspired by the [NeurotechEDU tutorial](http://learn.neurotechedu.com/preprocessing/) on EEG-preprocessing. Yu can always refer to that site for additional, perhaps more detailed, materials on the techniques shown here. \n",
    "\n",
    "We will be using the Python MNE library in this example: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What Is Preprocessing?\n",
    "\n",
    "In general, preprocessing is the procedure of transforming **raw data** into a something that is more suitable for further analysis. After preprocessing, data should be **easier to handle** (e.g., less outliers, less \"errors\"). \n",
    "\n",
    "With regard to EEG data, preprocessing is usually performed to **remove noise** and **get closer to** the **\"true\"** neural **signals** entailed in the \"messy\" EEG.\n",
    "\n",
    "<img align=\"left\" src=\"https://mne.tools/dev/_images/sphx_glr_10_overview_005.png\" alt=\"logo\" title=\"Github\" width=\"800\" height=\"800\" /> \n",
    "\n",
    "<img align=\"right\" src=\"https://mne.tools/dev/_images/sphx_glr_10_overview_006.png\" alt=\"logo\" title=\"Github\" width=\"800\" height=\"800\" /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why do we need preprocessing?\n",
    "\n",
    " ... several reasons ...\n",
    " - 1) The signals that are picked up from the scalp are not necessarily an accurate representation of the signals originating from the brain (e.g., missing spatial information).\n",
    " - 2) EEG data contains **a lot of noise** which can obscure weaker EEG signals (cf. true signal). \n",
    " - 3) Artifacts such as **eye blinks** or **muscle movement** can contaminate the data and distort the picture.\n",
    " - 4) We want to **separate the relevant neural signals from random activity** that occurs during EEG recordings (cf. true signal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Typical steps in EEG preprocessing\n",
    "\n",
    "- Using [MNE-python](https://mne.tools/stable/overview/cookbook.html):\n",
    "    - https://mne.tools/dev/auto_tutorials/intro/10_overview.html\n",
    "\n",
    "<center><img src=\"https://mne.tools/stable/_images/flow_diagram.svg\" width=\"800\" height=\"800\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hands-on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# import mne\n",
    "\n",
    "import mne\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### First, load one of the MNE example datasets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "path = mne.datasets.eegbci.load_data(3, 1)\n",
    "path[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now lets read (i.e., import) the EDF file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_edf(path[0], preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "raw.info['chs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from mne.datasets import eegbci\n",
    "\n",
    "# set channel names\n",
    "eegbci.standardize(raw)\n",
    "\n",
    "# set montage\n",
    "montage = mne.channels.make_standard_montage('standard_1020')\n",
    "raw.set_montage(montage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "raw.plot_sensors(kind='3d');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now that the *Raw file* has been created, we can plot the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "raw.plot(scalings = dict(eeg=200e-6));  # +/- 200 µV scale (1 V = 1000000 µV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Note:\n",
    "\n",
    "(just for demonstration purposes, you can skip this if you like, continue in 11.1)\n",
    "\n",
    "It is also possible to create a raw file from scratch, given the channel names, sample frequency, and an array of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ch_names = ['A', 'B'] # channel names\n",
    "sfreq = 200 # sampling frequency, in hertz\n",
    "info = mne.create_info(ch_names, sfreq) # See docs for full list of Info options.\n",
    "samples = np.array([[-1, 0, -1, 1, 1], [0, 1, 0, -1, 0]]) # Samples for each channel\n",
    "loadedRaw = mne.io.RawArray(samples, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "loadedRaw.plot(scalings='auto');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Look at characteristics of the *Raw file*\n",
    "\n",
    "E.g., look at the power spectral density plot of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "raw.plot_psd(tmin=0, tmax=60, fmin=2, fmax=80, average=True, spatial_colors=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Filtering\n",
    "\n",
    "Now that we have the raw data, we can filter the data to select the frequencies we're interested in.   \n",
    "   1. We want to remove the 60 Hz power line noise. If we want to \"remove 60Hz\" but keep other frequncies, we can use a notch filter [see here](https://jasmainak.github.io/mne-workshop-brown/preprocessing/filtering.html) for instance.\n",
    "   2. Alternatively, if we want a  a filter that \"lets pass\" all the frequencies below 60 Hz but removes everithing else, we can use a \"low-pass filter\". Here we can set an \"upper cut-off\" for the filter by setting `h_freq=50.0`. I use a conservative 50.0 Hz cut-off (and not 60.0 Hz) because filters have transition bandwidth, meaning that they will \"affect\" frequencies around the target frequency to a certain degree, but not remove them completely (i.e., the `passband edge` will be somewhat avobe the target frequency, see filter summary in the next slides).\n",
    "   3. Conversely, we can use a \"high-pass filter\" to remove frequencies below a certain frequency. Combined, high and low pass filters constitue a \"band-pass filter\" (i.e., lets a certain band of frequecies pass.)\n",
    "\n",
    "You can [see here](https://mne.tools/stable/auto_tutorials/preprocessing/25_background_filtering.html?highlight=filter) for more information on filters and implementation in MNE-Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# set notch filter\n",
    "raw.notch_filter(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we can remove very high and very low frequencies that are unlikely to contain the signal that is relevant to us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "raw.filter(l_freq=1.0, h_freq=50.0) # only keeping frequencies between 1-50 Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Notice how filtering changes the shape of the power spectral density plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "raw.info['sfreq']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now downsample the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Downsample a lot\n",
    "raw.resample(120, npad='auto')\n",
    "raw.plot_psd(tmin=0, tmax=60, fmin=2, fmax=60, average=False, spatial_colors=True, xscale='log');\n",
    "# Notice that the max plotted frequency is 60, the nyquist rate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "After filtering and downsampling, we can look at the raw data again to see if there are any bad channels:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "raw.plot(scalings = dict(eeg=200e-6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You may notice from the plot above that the channel C4 looks significantly noisier than the others. We can then flag it as a 'bad' channel and remove it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "raw.info['bads'] = ['C4']\n",
    "picks = mne.pick_types(raw.info, exclude='bads')\n",
    "raw.plot(scalings=dict(eeg=200e-6), bad_color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now that we have marked a channel as bad, we can interpolate the data coming from that channel via spherical spline interpolation. \n",
    "\n",
    "In order to be able to do that, we need to make sure that our channels have location information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(raw.info['chs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can see that all the locations (the 'loc' attributes) are at 0, meaning that we don't have accurate location info. However, assuming that the data was recorded from a headset using the standard 10-20 system, we can load a pre-configured channel location file and use that instead. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we can interpolate the bad channel and see what the reconstructed channel looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "raw.interpolate_bads(reset_bads=True)\n",
    "raw.plot(scalings=dict(eeg=200e-6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now that we have somewhat cleaned-up data, we can run ICA to try and localize the signal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from mne.preprocessing import ICA\n",
    "# play around with this number to get components \n",
    "# that seem to represent the actual brain activations well\n",
    "num_components = 15 \n",
    "ica = ICA(n_components=num_components, method='fastica')\n",
    "ica.fit(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Once the components have been computed, we can plot them on a model of the scalp: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ica.plot_components();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can now reject components that appear artifactual. To do so, we can visualize each component's properties first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "raw.plot(n_channels=32, scalings=dict(eeg=100e-6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This might seem like a lot of information. One commonly used heuristic is looking at the spectum of each component. Ideally, each spectrum will have a $\\dfrac 1 x$ - like shape: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ica.plot_properties(raw, picks=0); # This exact component number probably won't work if you recompute ICA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "...while outlier components will have increasing intensity for higher frequencies, like in this example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ica.plot_properties(raw, picks=9); # This exact component number probably won't work if you recompute ICA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can now see what our data looks like with the bad component removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ica.plot_overlay(raw, exclude=[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.exclude = [0]\n",
    "ica.apply(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot(scalings=dict(eeg=200e-6));"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
